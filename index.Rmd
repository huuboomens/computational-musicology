---
title: "Characteristics in Jazz styles"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
    storyboard: true
---

```{r setup, include=FALSE}
library(flexdashboard)
```


```{r}
library(tidyverse)
library(spotifyr)
library(compmus)

Sys.setenv(SPOTIFY_CLIENT_ID = 'fa5df116b34e4a778f295a41cd8d258b')
Sys.setenv(SPOTIFY_CLIENT_SECRET = 'd37387cf974844cebe470406970c19ee')

bebop <- get_playlist_audio_features('thesoundsofspotify', '55s8gstHcaCyfU47mQgLrB')
swing <- get_playlist_audio_features('thesoundsofspotify', '20CFvOMJgvNmysKxUH5GJV')
cool <- get_playlist_audio_features('thesoundsofspotify', '3RtFvzIXD7ulUCXkWdIOWW')

jazzstyles <-
    bebop %>% mutate(playlist = "bebop") %>%
    bind_rows(swing %>% mutate(playlist = "swing")) %>%
    bind_rows(cool %>% mutate(playlist = "cool"))
```

### Harmony

```{r}
circshift <- function(v, n) {if (n == 0) v else c(tail(v, n), head(v, -n))}
                                    
    # C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B 
major_chord <- 
    c(1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <- 
    c(1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <- 
    c(1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)
major_key <- 
    c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
    c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)
chord_templates <-
    tribble(
        ~name  , ~template,
        'Gb:7'  , circshift(seventh_chord,  6),
        'Gb:maj', circshift(major_chord,    6),
        'Bb:min', circshift(minor_chord,   10),
        'Db:maj', circshift(major_chord,    1),
        'F:min' , circshift(minor_chord,    5),
        'Ab:7'  , circshift(seventh_chord,  8),
        'Ab:maj', circshift(major_chord,    8),
        'C:min' , circshift(minor_chord,    0),
        'Eb:7'  , circshift(seventh_chord,  3),
        'Eb:maj', circshift(major_chord,    3),
        'G:min' , circshift(minor_chord,    7),
        'Bb:7'  , circshift(seventh_chord, 10),
        'Bb:maj', circshift(major_chord,   10),
        'D:min' , circshift(minor_chord,    2),
        'F:7'   , circshift(seventh_chord,  5),
        'F:maj' , circshift(major_chord,    5),
        'A:min' , circshift(minor_chord,    9),
        'C:7'   , circshift(seventh_chord,  0),
        'C:maj' , circshift(major_chord,    0),
        'E:min' , circshift(minor_chord,    4),
        'G:7'   , circshift(seventh_chord,  7),
        'G:maj' , circshift(major_chord,    7),
        'B:min' , circshift(minor_chord,   11),
        'D:7'   , circshift(seventh_chord,  2),
        'D:maj' , circshift(major_chord,    2),
        'F#:min', circshift(minor_chord,    6),
        'A:7'   , circshift(seventh_chord,  9),
        'A:maj' , circshift(major_chord,    9),
        'C#:min', circshift(minor_chord,    1),
        'E:7'   , circshift(seventh_chord,  4),
        'E:maj' , circshift(major_chord,    4),
        'G#:min', circshift(minor_chord,    8),
        'B:7'   , circshift(seventh_chord, 11),
        'B:maj' , circshift(major_chord,   11),
        'D#:min', circshift(minor_chord,    3))
key_templates <-
    tribble(
        ~name    , ~template,
        'Gb:maj', circshift(major_key,  6),
        'Bb:min', circshift(minor_key, 10),
        'Db:maj', circshift(major_key,  1),
        'F:min' , circshift(minor_key,  5),
        'Ab:maj', circshift(major_key,  8),
        'C:min' , circshift(minor_key,  0),
        'Eb:maj', circshift(major_key,  3),
        'G:min' , circshift(minor_key,  7),
        'Bb:maj', circshift(major_key, 10),
        'D:min' , circshift(minor_key,  2),
        'F:maj' , circshift(major_key,  5),
        'A:min' , circshift(minor_key,  9),
        'C:maj' , circshift(major_key,  0),
        'E:min' , circshift(minor_key,  4),
        'G:maj' , circshift(major_key,  7),
        'B:min' , circshift(minor_key, 11),
        'D:maj' , circshift(major_key,  2),
        'F#:min', circshift(minor_key,  6),
        'A:maj' , circshift(major_key,  9),
        'C#:min', circshift(minor_key,  1),
        'E:maj' , circshift(major_key,  4),
        'G#:min', circshift(minor_key,  8),
        'B:maj' , circshift(major_key, 11),
        'D#:min', circshift(minor_key,  3))
```
```{r}
alone_together <- 
    get_tidy_audio_analysis('3GOZbK2epuHzCt5YvvVFHO') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan'))
    


alone_together %>% 
    compmus_match_pitch_template(key_templates, 'euclidean', 'manhattan') %>% 
    ggplot(
        aes(x = start + duration / 2, width = duration, y = name, fill = d)) +
    geom_tile() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_minimal() +
    labs(x = 'Time (s)', y = '')

so_what <- 
    get_tidy_audio_analysis('4vLYewWIvqHfKtJDk8c8tq') %>% 
    compmus_align(sections, segments) %>% 
    select(sections) %>% unnest(sections) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'rms', norm = 'euclidean'))
    


so_what %>% 
    compmus_match_pitch_template(key_templates, 'euclidean', 'manhattan') %>% 
    ggplot(
        aes(x = start + duration / 2, width = duration, y = name, fill = d)) +
    geom_tile() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_minimal() +
    labs(x = 'Time (s)', y = '')

take_five <- 
    get_tidy_audio_analysis('1YQWosTIljIvxAgHWTp7KP') %>% 
    compmus_align(sections, segments) %>% 
    select(sections) %>% unnest(sections) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan'))
    


take_five %>% 
    compmus_match_pitch_template(key_templates, 'euclidean', 'manhattan') %>% 
    ggplot(
        aes(x = start + duration / 2, width = duration, y = name, fill = d)) +
    geom_tile() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_minimal() +
    labs(x = 'Time (s)', y = '')
```
I wanted to try to show some differences between harmony in cool jazz and previous styles. Although the harmonies of the cool era are similar to that of the previous styles, there are a few new trends, like more classical orientated harmony and also modal harmony. A lot of modal tunes consist of large sections of just one chord, instead of the more usual tonal progressions, and this is something I hoped to show with keygrams en chordograms. However I could not find examples that worked. Actually I couldn't even find tracks where the key or a progression at any point was clear from the plot, even not in a "one chord tune" like Miles Davis' So What. I think the reason for this is that jazz harmony is usually at least five-part. This means there five, six, or even seven independed harmonic voices from which the chords are built. This makes makes it really hard to detect the harmony especially with a walking bass. A solution for this could be to not only detect the pitch classes, but also show in what order the pitches are constructed. In jazz harmony the thirds and sevens are almost always voiced on the low side, as these make the basic harmonic progression clear, while the other voices, also reffered to as extensions, are used for coloring on top. This way the harmony is perfectly clear eventhough the chords have a lot of notes. I added some the examples of tracks that I tried to interpret. First to last are: Alone Together by Kenny Dorham, So What by Miles Davis and Take Five by the Dave Brubeck quartet.

### introduction

```{r}
danceability_bebop <-
  bebop %>% summarise(M = mean(danceability, na.rm = TRUE), SD =               sd(danceability, na.rm = TRUE))
danceability_swing <-
  swing %>% summarise(M = mean(danceability, na.rm = TRUE), SD =               sd(danceability, na.rm = TRUE))
danceability_cool <-
 cool %>% summarise(M = mean(danceability, na.rm = TRUE), SD =               sd(danceability, na.rm = TRUE))
danceability <-
 danceability_bebop %>% mutate(playlist = "bebop") %>%
 bind_rows(danceability_cool %>% mutate(playlist = "cool")) %>%
 bind_rows(danceability_swing %>% mutate(playlist = "swing"))


energy_bebop <-
  bebop %>% summarise(M = mean(energy, na.rm = TRUE), SD =                     sd(energy, na.rm = TRUE))
energy_swing <-
  swing %>% summarise(M = mean(energy, na.rm = TRUE), SD =                     sd(energy,       na.rm = TRUE))
energy_cool <-
  cool %>% summarise(M = mean(energy, na.rm = TRUE), SD =                     sd(energy, na.rm = TRUE))
energy <-
 energy_bebop %>% mutate(playlist = "bebop") %>%
 bind_rows(energy_cool %>% mutate(playlist = "cool")) %>%
 bind_rows(energy_swing %>% mutate(playlist = "swing"))
  

loudness_bebop <-  
bebop %>% summarise(M = mean(loudness, na.rm = TRUE), SD = sd(loudness, na.rm = TRUE))
loudness_swing <-
swing %>% summarise(M = mean(loudness, na.rm = TRUE), SD = sd(loudness, na.rm = TRUE))
loudness_cool <-
cool %>% summarise(M = mean(loudness, na.rm = TRUE), SD = sd(loudness, na.rm = TRUE))
loudness <-
 loudness_bebop %>% mutate(playlist = "bebop") %>%
 bind_rows(loudness_cool %>% mutate(playlist = "cool")) %>%
 bind_rows(loudness_swing %>% mutate(playlist = "swing"))

valence_bebop <-
bebop %>% summarise(M = mean(valence, na.rm = TRUE), SD = sd(valence))
valence_swing <-
swing %>% summarise(M = mean(valence, na.rm = TRUE), SD = sd(valence))
valence_cool <-
cool %>% summarise(M = mean(valence, na.rm = TRUE), SD = sd(valence))
valence <-
 valence_bebop %>% mutate(playlist = "bebop") %>%
 bind_rows(valence_cool %>% mutate(playlist = "cool")) %>%
 bind_rows(valence_swing %>% mutate(playlist = "swing"))

tempo_bebop <-
bebop %>% summarise(M = mean(tempo, na.rm = TRUE), SD = sd(tempo, na.rm = TRUE))
tempo_swing <-
swing %>% summarise(M = mean(tempo, na.rm = TRUE), SD = sd(tempo, na.rm = TRUE))
tempo_cool <-
cool %>% summarise(M = mean(tempo, na.rm = TRUE), SD = sd(tempo, na.rm = TRUE))
tempo <-
 tempo_bebop %>% mutate(playlist = "bebop") %>%
 bind_rows(tempo_cool %>% mutate(playlist = "cool")) %>%
 bind_rows(tempo_swing %>% mutate(playlist = "swing"))
```
```{r}
danceability %>%
   ggplot(aes(x = playlist, y = M)) + geom_bar(stat = "identity") + labs(title = 'danceability')

energy %>%
  ggplot(aes(x = playlist, y = M)) + geom_bar(stat = "identity") + labs(title = 'energy')

loudness %>%
  ggplot(aes(x = playlist, y = M)) + geom_bar(stat = "identity") + labs(title = 'loudness')

valence %>%
  ggplot(aes(x = playlist, y = M)) + geom_bar(stat = "identity") + labs(title = 'valence')

tempo %>%
  ggplot(aes(x = playlist, y = M)) + geom_bar(stat = "identity") + labs(title = 'tempo')
```

***
For my portfolio I want to check out and compare playlists of different jazz genres, and see whether Spotify recognizes similar characteristic differences between the styles in their measured features as expected in these genres. The playlist I am going to use are the "sound of.." playlists. For this comparison it seems to me that the best styles to research are the most common and famous and big directions in jazz: swing, bebop, cool jazz. A difference to expect would for example be danceability between swing and cool jazz, as swing originated as dance music and later jazz changed more to a concert style of music. In order to do so I took the means of features that seemed relevant to see if there were any points of interest.

The comparison between cool jazz and swing does however give the expected results. Danceability, energy and valence are higher in swing, as one would expect it to be in dance music. Also there are less tunes with odd time signature in swing, which I’d say would also be more expected in dance music. I noticed however that one of the tunes that was listed as odd time signature tune in the bebop list was Take Five by the Dave Brubeck Quartet. I don’t think that Take Five could be classified as bebop tune in anyway, so this raises the question whether these list are made carefully enough and with what criteria the tunes are divided among the styles.
***



### Scatterplots

```{r}
jazzstyles %>%
  ggplot(aes(x = valence, y = energy, color = playlist)) + geom_point()

jazzstyles %>%
  ggplot(aes(x = danceability, y = tempo, color = playlist)) + geom_point()
```

***
These two scatterplots visualize the findings from the first assignment. The differences between the styles are as expected, although the differences are not actually that big: swing is more danceable and has more valence than bebop and cooljazz and energy is lowest in cooljazz. A point of interest is that the scatterplot of energy and valence seems to suggest a positive correlation between the two. Although this is ofcourse not enough evidence, this could mean that Spotify uses one of these features to compute the other one.
***

### Chroma and timbre

```{r}
rosita <- 
    get_tidy_audio_analysis('3tzOXO0tEqbI4SCrSDhZ4J') %>% 
    select(segments) %>% unnest(segments) %>% 
    select(start, duration, pitches)

rosita %>% 
    mutate(pitches = map(pitches, compmus_normalise, 'euclidean')) %>% 
    compmus_gather_chroma %>% 
    ggplot(
        aes(
            x = start + duration / 2, 
            width = duration, 
            y = pitch_class, 
            fill = value)) + 
    geom_tile() +
    labs(x = 'Time (s)', y = NULL, fill = 'Magnitude') +
    theme_minimal()
```

```{r}
rosita <- 
    get_tidy_audio_analysis('3tzOXO0tEqbI4SCrSDhZ4J') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan')) %>% 
    mutate(
        timbre = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean',))

rosita %>% 
    compmus_self_similarity(pitches, 'manhattan') %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '')

confirmation <- 
    get_tidy_audio_analysis('7pNfEYVT7Sfs9PDPIuzusc') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan')) %>% 
    mutate(
        timbre = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean',))

confirmation %>% 
    compmus_self_similarity(pitches, 'manhattan') %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '')

```

